{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\r\n",
      "Your branch is up-to-date with 'origin/master'.\r\n",
      "\r\n",
      "Untracked files:\r\n",
      "  (use \"git add <file>...\" to include in what will be committed)\r\n",
      "\r\n",
      "\t\u001b[31m.ipynb_checkpoints/\u001b[m\r\n",
      "\t\u001b[31mSeq2Seq-Beijing-Learn.ipynb\u001b[m\r\n",
      "\r\n",
      "nothing added to commit but untracked files present (use \"git add\" to track)\r\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From https://github.com/Adrian-Gordon/seq2seq-sagemaker\r\n",
      " * branch            master     -> FETCH_HEAD\r\n",
      "Already up-to-date.\r\n"
     ]
    }
   ],
   "source": [
    "!git pull origin master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "{\n",
      "\"data_modulename\":\"generate_beijing_data\",\n",
      "\"datafilename\": \"./data/PRSA_data_2010.1.1-2014.12.31.csv\",\n",
      "\"savefilename\":\"beijing-seq2seq0\",\n",
      "\"input_sequence_length\": 30,\n",
      "\"output_sequence_length\": 5,\n",
      "\"batch_size\" :16,\n",
      "\"input_dim\" : 11,\n",
      "\"output_dim\":1,\n",
      "\"num_stacked_layers\" :2,\n",
      "\"hidden_dim\" :64,\n",
      "\"learning_rate\" :0.01,\n",
      "\"l2_regularization_lambda\":0.03,\n",
      "\"gradient_clipping\": 2.5,\n",
      "\"epochs\": 100\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "import boto3\n",
    "\n",
    "import json\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "bucket='culturehub'\n",
    "\n",
    "#get the data\n",
    "data_key = 'seqtoseq/PRSA_data_2010.1.1-2014.12.31.csv'\n",
    "data_location = 's3://{}/{}'.format(bucket, data_key)\n",
    "\n",
    "#get the configuration\n",
    "\n",
    "configuration_key ='seqtoseq/config_beijing.json'\n",
    "configuration_location = 's3://{}/{}'.format(bucket, configuration_key)\n",
    "\n",
    "configuration_string = boto3.resource('s3').Object(bucket, configuration_key).get()['Body'].read().decode('utf-8')\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(configuration_string)\n",
    "\n",
    "config = json.loads(configuration_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://culturehub/seqtoseq/PRSA_data_2010.1.1-2014.12.31.csv\n",
      "   No  year  month  day  hour     pm2.5      DEWP      TEMP      PRES  \\\n",
      "0   1  2010      1    1     0 -1.018534 -1.580878 -1.922250  0.443328   \n",
      "1   2  2010      1    1     1 -1.018534 -1.580878 -2.004228  0.345943   \n",
      "2   3  2010      1    1     2 -1.018534 -1.580878 -1.922250  0.248559   \n",
      "3   4  2010      1    1     3 -1.018534 -1.580878 -2.168183  0.248559   \n",
      "4   5  2010      1    1     4 -1.018534 -1.511594 -2.004228  0.151174   \n",
      "\n",
      "        Iws        Is        Ir  cbwd_NE  cbwd_NW  cbwd_SE  cbwd_cv  \n",
      "0 -0.441894 -0.069353 -0.137667        0        1        0        0  \n",
      "1 -0.379306 -0.069353 -0.137667        0        1        0        0  \n",
      "2 -0.343514 -0.069353 -0.137667        0        1        0        0  \n",
      "3 -0.280926 -0.069353 -0.137667        0        1        0        0  \n",
      "4 -0.218339 -0.069353 -0.137667        0        1        0        0  \n"
     ]
    }
   ],
   "source": [
    "#get the data\n",
    "\n",
    "from generatedata import *\n",
    "\n",
    "bucket='culturehub'\n",
    "data_key = 'seqtoseq/PRSA_data_2010.1.1-2014.12.31.csv'\n",
    "data_location = 's3://{}/{}'.format(bucket, data_key)\n",
    "gd=GenerateData(data_location)\n",
    "print(gd.data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.1989867471855264\n",
      "1 2.851043589841268\n",
      "2 6.408480212202025\n",
      "3 2.218532951238478\n",
      "4 1.5419816817504302\n",
      "5 1.0480882908541442\n",
      "6 1.519546285227316\n",
      "7 1.8213039050238269\n",
      "8 0.841788959575196\n",
      "9 0.8471662316804788\n",
      "10 0.8529783823784529\n",
      "11 0.9965009154918675\n",
      "12 1.3454427006791738\n",
      "13 0.7795345504702291\n",
      "14 0.7818845017631202\n",
      "15 0.6915746839025418\n",
      "16 0.8583896188935266\n",
      "17 1.090032292970069\n",
      "18 0.7045560892999467\n",
      "19 0.7210055584257332\n",
      "20 0.6400730944077393\n",
      "21 0.9517587209512905\n",
      "22 0.6477928814937159\n",
      "23 0.6889379173328283\n",
      "24 0.8524288646717323\n",
      "25 0.7239621015889807\n",
      "26 0.600240578222153\n",
      "27 0.5351876518052611\n",
      "28 0.5625681270933027\n",
      "29 0.8849653208890069\n",
      "30 0.5353460073226219\n",
      "31 0.6028103915504657\n",
      "32 0.6127935454039085\n",
      "33 0.784477449675016\n",
      "34 0.9891543765544969\n",
      "35 0.45875740811719856\n",
      "36 0.5062837651524307\n",
      "37 0.8150321902297677\n",
      "38 0.48822178298055474\n",
      "39 0.46978266883254716\n",
      "40 0.5435536966157292\n",
      "41 0.4966749185579714\n",
      "42 0.4520366198578858\n",
      "43 0.4415711814148492\n",
      "44 0.4749181625123694\n",
      "45 0.5310222850421795\n",
      "46 0.4257183860307711\n",
      "47 0.3720159409047606\n",
      "48 0.42660145540677186\n",
      "49 0.45742542562837396\n",
      "50 0.5276366426140972\n",
      "51 0.48919070930703207\n",
      "52 0.38447408404926786\n",
      "53 0.48347840703410866\n",
      "54 0.34384996791909905\n",
      "55 0.34627984303084963\n",
      "56 0.35941890746538563\n",
      "57 0.36185184958081484\n",
      "58 0.38131771444707363\n",
      "59 0.33770605505799334\n",
      "60 0.5269370565369226\n",
      "61 0.40033484593294244\n",
      "62 0.33577656673943235\n",
      "63 0.29450538307483554\n",
      "64 0.2821932111054941\n",
      "65 0.35116990806716236\n",
      "66 0.3357477011224038\n",
      "67 0.4024541894305212\n",
      "68 0.3358766418917231\n",
      "69 0.3266326588566969\n",
      "70 0.32036505007046195\n",
      "71 0.33912418762241914\n",
      "72 0.35001263695267026\n",
      "73 0.28255310818559143\n",
      "74 0.24190586946880407\n",
      "75 0.3099989395194981\n",
      "76 0.2725555316834308\n",
      "77 0.3606359399971223\n",
      "78 0.3027629533897893\n",
      "79 0.5939901862714013\n",
      "80 0.37046485466262036\n",
      "81 0.24580895676239423\n",
      "82 0.22109753138531427\n",
      "83 0.24745207334191147\n",
      "84 0.24764835286259368\n",
      "85 0.29920062375896744\n",
      "86 0.809296882806837\n",
      "87 0.20562770765704094\n",
      "88 0.20461894675557876\n",
      "89 0.21195424590529854\n",
      "90 0.2680698383434055\n",
      "91 0.199665399311364\n"
     ]
    }
   ],
   "source": [
    "#learn\n",
    "\n",
    "from seq2seqmodel import *\n",
    "\n",
    "import os\n",
    "\n",
    "def main():\n",
    "    \n",
    "    \n",
    "    seq2seq  = Seq2Seq(config)\n",
    "\n",
    "    loss_summary = tf.summary.scalar(\"loss\", seq2seq.loss)\n",
    "    merged = tf.summary.merge_all()\n",
    "\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "  \n",
    "    with tf.Session() as sess:\n",
    "   \n",
    "        sess.run(init)\n",
    "\n",
    "        for epoch in range(config[\"epochs\"]):\n",
    "\n",
    "     \n",
    "            writer = tf.summary.FileWriter('./graphs/seq2seq/basic', sess.graph)\n",
    "\n",
    "            #generate a data batch\n",
    "            input_batch, output_batch = gd.getTrainingSample(batch_size = config[\"batch_size\"], input_seq_length =config[\"input_sequence_length\"], output_seq_length = config[\"output_sequence_length\"])\n",
    "\n",
    "            reshaped_input_batch = gd.reshape(np.array(input_batch),config[\"input_sequence_length\"], config[\"input_dim\"])\n",
    "\n",
    "     \n",
    "            reshaped_output_batch = gd.reshape(np.array(output_batch),config[\"output_sequence_length\"], config[\"output_dim\"])\n",
    "\n",
    "            feed_dict={seq2seq.encoder_inputs[t]: reshaped_input_batch[t] for t in range(config[\"input_sequence_length\"])}\n",
    "\n",
    "            feed_dict.update({seq2seq.decoder_target_inputs[t]: reshaped_output_batch[t] for t in range(config[\"output_sequence_length\"])})\n",
    "     \n",
    "\n",
    "            #the_decoder_outputs = sess.run(seq2seq.encode_decode,feed_dict)\n",
    "\n",
    "            _, loss = sess.run([seq2seq.optimize, seq2seq.loss],feed_dict)\n",
    "\n",
    "            summary = sess.run(merged,feed_dict)\n",
    "            writer.add_summary(summary, epoch)\n",
    "     \n",
    "            print(epoch,loss)\n",
    "   \n",
    "        saver = tf.train.Saver\n",
    "        save_path = saver().save(sess, os.path.join('./',config[\"savefilename\"]))\n",
    "        print(\"Checkpoint saved at: \", save_path)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
